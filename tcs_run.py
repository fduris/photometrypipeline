#!/usr/bin/env python3 

# TODO:
# 

import argparse
from argparse import ArgumentParser
from argparse import RawDescriptionHelpFormatter
import textwrap

parser = ArgumentParser(formatter_class=RawDescriptionHelpFormatter, description=textwrap.dedent('''\

|----------------------------------------------|
| tcs_run = PHOTOMETRYPIPELINE for TCS/MuSCAT2 |
|----------------------------------------------|
           
ARGUMENTS:
tcs_run [--target STR] [--filter STR] [--fixed-aprad FLT] [--solar] 
        { -------------- PHOTOMETRYPIPELINE params ---------------} 
      
        [--backup {none, filter, time, sex}] [--use-filter {a,g,r,i,z_s}] [--use-time] 
        { ------------------------- tcs_run backup params ---------------------------}
      
        [--dplots] [--iplots] [--zscale]
        { -------------------------- tcs_run plots params ---------------------------}

        [--force] [--force-failed] [--iters INT] [--gzip] [--starfield] [--compat]
        { -------------------------- tcs_run other params ---------------------------}

        FILE
      
GENERAL:
  The script repeatedly runs the pp_run command from PHOTOMETRYPIPELINE in order to obtain 
  better/more results. 

  It appears that there is an interaction between sextractor and SCAMP through *.head files. The 
  head files are generated by SCAMP, contain information from fits file header (WCS, distortion,...) 
  and can be read by the sextractor. Originally, SCAMP is executed after sextractor in the PHOTO-
  METRYPIPELINE, so this kind of interaction is not possible. However, repeated run of the pp_run 
  enables this interaction which often leads to better results and/or more registered files.

  Additionally, *.head file can be supplied from other sources like other filters or previous/later
  time. Some alignment of images may need to be performed before.
  
RESULTS:
  The script does not change the given fits file. Instead, it creates a new directory with the files 
  name (omitting the .fits extension) in place where the file is located, copies the fits file into 
  this directory and moves all computations there.
  
  Inside the compatation directory, the script creates a new directory for each execution of pp_run. The 
  names are run1, run2, run3 etc. In each run* folder, there is standard output (out.txt) and error 
  output (err.txt) of the pp_run. Additionally, the script copies sextractor (*.ldac) and SCAMP (*.ldac.db) 
  outputs, if they exists, and converts them to tsv files. Finally, if the registration was successful, 
  the script copies all results of the current pp_run execution (*.dat files) into the current run directory.
  
  If the script could not register the file, a file with the name FAILED is placed into the computation 
  directory. If the registration was successfull, the script will create:
  1) *.tsv file with the all photometry pipeline results (combined *.dat files)
  2) *.json file that contains results from all runs

  The plots, if selected will be stored in the main computation directory.
   
IMPORTANT:
  For the script to work, it needs to be used with the bundled PHOTOMETRYPIPELINE. This version has 
  been modified in the following way. Lines from 286 to 322 in pp_register.py component were commented 
  out. Note that these lines may change in future versions. What needs to be removed is the loop
      "for filename in goodfits:"
  after
      "logging.info('update image headers with WCS solutions ')"

  New parameters -sex and -starfield were added to pp_run.py, and new parameter -sex was added to 
  pp_register.py and pp_extract.py. Parameter -starfield is explained below. Paramter -sex tells the
  internaly used sextractor to run in the two-image mode, one for the source extraction and one for
  the photometry. More details below.

tcs_run PARAMETERS:
  file   - Name of the fits file to process. Only one file can be specified.
  
  backup - This option indicates what to do when the initial registration fails. Options are none 
           (default), filter, time and sex. 
           
           filter: This option will try to copy *.head file from a successfully registered image in
                   other filters at the same time. Filter can be specified by --use-filter option.
                   Otherwise, the filter are tried in the order (g, r, i, z_s).
                   No alignment of images is performed.

            time:  Analogous to the filter option but instead of looking through filters, the script
                   inspects 2 images before and after the current (if they exists). Closer images
                   are preferred. No alignment of images is performed.

            sex:   Use the sextractor two-image mode. This option must be supplemented with either
                   --use-time or --use-filter option. In case of --use-filter, the current image is
                   aligned to the image from the specified filter (if it was successfully registered).
                   Then, the *.head file of the supplemented image is copied to the current computation
                   directory, and arguments are passed to pp_run to use the sextractor in two-image 
                   mode (new -sex param in pp_run.py).
                   In case of --use-time, two images before and two after the current image are aligned,
                   stacked, and passed to the pp_run as in the case of --use-filter. No *.head file is
                   copied in this case (i.e., there is no requirement on the registration of the used
                   images).

  use-filter - Specifies the filter to be used for the backup options filter and sex with. The default
           value is 'a' is for automatic mode in the order (g, r, i, z_s).
           
  iters  - Set the maximum number of pp_run repeats. The repeats stop by themselves
           if the registration fails first three runs, or
           if the improvement in AS_CONTRAST and XY_CONTRAST is smaller than 1 in two consecutive runs.
           
  force  - Before computation, the script checks, if the file was not processed previously. If there is a 
           a *.tsv file with results, the script will stop. If there is a computation folder but no results
           file and no backup is specified, the script stops. 
           This can be overriden by setting --force option. In this case, computation folder belonging 
           to this file will be deleted, and the computation will be run anew.
            
  force-failed  - Same as option --force but only for failed files (no *.tsv file with results).
           
  dplots - If set, the script will create detection plot for each pp_run call. The plots are stored in the 
           detections.pdf file in the computation directory. The plots contain sextractor detected light 
           sources (red circles) overlaid on the fits file image (zscaled). Additionally, if the registration 
           was successful, blue circles indicate those light sources that were registered. Additionally,
           if backup sex with filter option was selected, green circles will indicate registered sources
           of the supplemented file.

  zscale - If set, the background fits image in dplots will be zscaled.
           
  iplots - If set, the script will create iteration plots. These plots show how AS_CONTRAST, XY_CONTRAST and 
           RA, DEC and MAG variables changed with each execution of pp_run. However, even though the 
           AS_CONTRAST and XY_CONTRAST can improve dramatically, there is usually very little change in 
           either astrometry or photometry of the target and reference star.
           
  gzip   - If set, PYPER will try to save space by removing the copied *.fits file and compressing the 
           computation directory.

  starfield - Use this option for images of star fields. In this case, the missing target will ignored,
           and in the *.tsv file with results, the target columns will be set to zero.

PHOTOMETRYPIPELINE PARAMETERS:           
  target - Optionally, set target name to overwrite the OBJECT keyword in the fits file header. Sometimes, 
           the stored target name in the fits file header is not correct (e.g., missing underline "_" sign).
           If this happens, script flags the file as FAILED. It will be detected by missing *.dat file for 
           the target.
           
  filter - Manual filter name override for the photometric calibration step.
  
  fixed-aprad - Use this fixed apereture radius for all data instead of finding the aperture radius in a 
           curve-of-growth analysis.
           
  solar  - If set, the photometric calibration is only using stars with solar-like colors (see pp_calibrate 
           documentation for details).
           
EXAMPLES:
  The most common is to run the command as follows, which will extract the target name from the fits file, 
  use default photometry pipeline parameters and produce plots:
  
    tsc_run FILE --dplots [--zscale] --iplots  
    
  To skip the plots, use only
  
    tsc_run FILE
  
  To override the object name, use the --target option as follows:
  
    tsc_run FILE --target TARGET

  For starfields, use

    tsc_run FILE --starfield
    
  If the previous computation failed and only for those that failed, you can specify a backup option. For
  details, see comments above. The --target option here is optional.
  
    tsc_run FILE --backup filter [--use-filter FILTER]
    tsc_run FILE --backup time
    tsc_run FILE --backup sex --use-filter FILTER
    tsc_run FILE --backup sex --use-time
    
  All or failed computations can be forced to reanalyse by setting on of the force options. Note that in 
  this case the --backup option does not apply because the computation is redone from the beginning.
  
    tsc_run FILE --force
    tsc_run FILE --force-failed
    
  To save space, fits files can be deleted and the computation dir can be compressed with
  
    tsc_run FILE --gzip
    
  To run the script for the whole folder, use this or similar (e.g., add target)
  
    for FILE in *.fits; do tsc_run $FILE --dplots --zscale --iplots;                 done
    for FILE in *.fits; do tsc_run $FILE --dplots --zscale --iplots --backup filter; done
    for FILE in *.fits; do tsc_run $FILE --dplots --zscale --iplots --backup time;   done
    for FILE in *.fits; do tsc_run $FILE --dplots --zscale --iplots --backup filter; done  

  To try with other filters in two-file mode in sextractor, use (for processing the g filter)

    for FILE in *.fits; do tsc_run $FILE --dplots --iplots --zscale --backup sex --sex-filter r; done
    for FILE in *.fits; do tsc_run $FILE --dplots --iplots --zscale --backup sex --sex-filter i; done
    for FILE in *.fits; do tsc_run $FILE --dplots --iplots --zscale --backup sex --sex-filter z_s; done
    for FILE in *.fits; do tsc_run $FILE --dplots --iplots --zscale --backup sex --sex-time; done
    
'''))
parser.add_argument('file',           type=str,                             help="Fits file to process")
parser.add_argument('--target',       type=str,            default='',      help="pp_run: target name to override the one from fits file")
parser.add_argument('--filter',       type=str,            default='',      help="pp_run: override filter name in photometric calibration")
parser.add_argument('--fixed-aprad',  type=float,          default=0,       help="pp_run: override aperture radius in sextractor")
parser.add_argument('--iters',        type=int,            default=10,      help="Number of max iterations (default 10)")
parser.add_argument('--backup',       type=str,            default='none',  help="Backup for failed registration (none, filter, time, sex). Default is none.")
parser.add_argument('--use-filter',   type=str,            default='a',     help="Filter for the backup == sex option, 'a' for automatic (default a)")
parser.add_argument('--use-time',     action='store_true',                  help="If present with backup == sex, time staking of images is used in sextractor")
parser.add_argument('--force',        action='store_true',                  help="If present, forces the ALL computation anew")
parser.add_argument('--force-failed', action='store_true',                  help="If present, forces the FAILED computation anew")
parser.add_argument('--dplots',       action='store_true',                  help="If present, make detection plots")
parser.add_argument('--zscale',       action='store_true',                  help="If present, fits image in dplots will be zscaled")
parser.add_argument('--iplots',       action='store_true',                  help="If present, make iteration plots")
parser.add_argument('--gzip',         action='store_true',                  help="If present, fits files are removed and the computation directory is compressed")
parser.add_argument('--solar',        action='store_true',                  help="If present, use only solar-like stars for calibration")
parser.add_argument('--starfield',    action='store_true',                  help="If present, ignore missing target")
parser.add_argument('--compat',       action='store_true',                  help="If present, will ignore missing starfield and non-standard target name")
args = parser.parse_args()


# make sure you do not look at starfield (in case it was not specified, and we have target name)
# also, args.compat skips this step for past compatibility where we had asteroids with names (e.g., Midas)
def isnumber(x):
    try:
        val = int(x)
    except ValueError:
        return False
    return True
#

if not args.compat and not args.starfield and not args.target == "":
    # asteroids have name of form YEAR_L+N* or just a number N+
    if not isnumber(args.target):
        # check the format YEAR_L+N*
        params = args.target.split('_')
        if len(params) == 1:
            # is starfield because it has no underscore
            args.starfield = True
        elif len(params[0]) != 4 or not isnumber(params[0]):
            # is starfield because initial number is not 4 digits long or is not a number
            args.starfield = True
        elif not params[1][0].isupper():
            # is starfield because after year and underscore, there should be a character
            args.starfield = True


args.iplots = args.iplots and not args.starfield

# some global vars used in the computation:
STARFIELD = args.starfield

# time depth in seconds for the backup option "time"
TDEPTH  = 2
# maximum number of iterations
ITERS   = args.iters
# parts of the fits filenames that identify the filter
FILTERS = ['MCT20', 'MCT21', 'MCT22','MCT23']
# pairing the filter folders and filter identifiers
FOLDERS = {'MCT20': 'g', 'MCT21': 'r', 'MCT22': 'i','MCT23': 'z_s'}
IFOLDERS= {'g': 'MCT20', 'r': 'MCT21', 'i': 'MCT22', 'z_s': 'MCT23'}
# field of view
DIM_X = 7.4/60 # deg
DIM_Y = 7.4/60 # deg
# special pp_run params
PP_SEX = ''

import os
import shutil
import glob

# prepare file and folder names:
# name of the fits file
base = os.path.basename(args.file)
# name of the fits file without extension
name = os.path.splitext(base)[0]
# absolute path of the fits file
path = os.path.abspath(os.path.dirname(args.file))
# tsv result files (indicates success)
SUCC = os.path.isfile(name + '/' + name + '.tsv')

# sanity checks
CURRENT_FILTER = FOLDERS[name.split('_')[2]]
if args.backup == 'sex' and args.use_filter == CURRENT_FILTER:
    print('WRONG USAGE: cannot use the current filter as guiding (check params --backup and --sex-filter)')
    os._exit(1)

if args.backup == 'sex' and args.use_filter not in ['a', 'g', 'r', 'i', 'z_s']:
    print('WRONG USAGE: unknown filter name (check param --sex-filter)')
    os._exit(1)


# if the computation is forced, check if the computation directory exists,
# and if so, remove it
if args.force and os.path.isdir(name):
    print('Removing the previous computation (--force option)')
    compDir = path + '/' + name
    shutil.rmtree(compDir)
    SUCC = False
# force FAILED files only
if args.force_failed and not SUCC:
    print('Removing the previous FAILED computation (--force-failed option)')
    compDir = path + '/' + name
    shutil.rmtree(compDir)
    SUCC = False

# check for previous computations:
# if the computation was successfully finished, skip it
if SUCC:
    print('File ' + base + ' already processed, stopping')
    os._exit(1)
# if it failed previously and there is no backup, skip it
elif os.path.isdir(name) and args.backup == 'none':
    print('File ' + base + ' FAILED with no backup, stopping')
    os._exit(1)
# if it failed previously, try other filters on the same time as backup
elif os.path.isdir(name) and args.backup == 'filter':
    # if specified, use only the given filter
    if not args.use_filter == 'a':
        # check if the given filter was successful
        nameParts = name.split('_')
        tempName = nameParts[0] + '_' + nameParts[1] + '_' + IFOLDERS[args.use_filter] + '_' + nameParts[3]
        tsvFile  = '../' +  args.use_filter + '/' + tempName + '/' + tempName + '.tsv'
        if not os.path.isfile(tsvFile):
            print('File ' + base + ' FAILED and the specified filter was not successfully registered')
            os._exit(1)
            # stop here
        FILTERS = [IFOLDERS[args.use_filter]]
    else:
        thisFilter = name.split('_')[2]
        FILTERS.remove(thisFilter)
    # check if other filters are successfully registered:
    # break the current fits file name, so that correcponding name of the new filter
    # can be constructed
    nameParts = name.split('_')
    # to mark success
    found = False
    for fi in FILTERS:
        # fits file name of the next filter
        tempName = nameParts[0] + '_' + nameParts[1] + '_' + fi + '_' + nameParts[3]
        # corresponding results file of the next filter
        # if this file exists, the registration was successful for the tried filter
        tsvFile  = '../' +  FOLDERS[fi] + '/' + tempName + '/' + tempName + '.tsv'
        # this is the file that is copied to the current computation directory,
        # if the registration was successful for the tried filter
        headFile = '../' +  FOLDERS[fi] + '/' + tempName + '/' + tempName + '.head'
        # check if the tsv file exists
        # if not, continue to the next filter
        if not os.path.isfile(tsvFile):
            continue
        # if the tsv file exists (meaning the rgistration was successful for some filter),
        if os.path.isfile(headFile):
            found = True
            break
    # if there was a successful filter
    if found:
        print('File ' + base + ' FAILED but trying with filter ' + FOLDERS[fi])
        # copy head file of the successful filter
        print('>> Copying new head file') 
        shutil.copyfile(headFile, name + '/' + name + '.head')
        # remove FAILED file
        print('>> Removing FAILED mark')
        try:
            os.remove(name + '/FAILED')
        except OSError:
            pass
        # remove old run* directories
        print('>> Removing old run* folders')
        for run in glob.glob(name + '/run*'):
            shutil.rmtree(run)
        # remove old diagnostics (pp_run tends to update some parts and not overwrite)
        print('>> Removing old diagnostics')
        try:
            os.remove(name + '/diagnostics.html')
        except OSError:
            pass
        shutil.rmtree(name + '/.diagnostics', ignore_errors=True)
    else:
        print('File ' + base + ' FAILED and no other filter has been registered yet')
        os._exit(1)
# if it failed previously, try close times in the same filter as backup
elif os.path.isdir(name) and args.backup == 'time':
    # list fits files in the same directory/filter
    fitsFiles = glob.glob("*.fits")
     # sort them by time
    fitsFiles = sorted(fitsFiles)
    # find the current file
    cur = fitsFiles.index(base)
    # find potential files that can help
    potential = list()
    for j in range(1, TDEPTH+1):
        # first look for files that are closest
        # look for immediate previous
        if cur > j-1:
            potential.append(fitsFiles[cur - j])
        # look for immediate after
        if cur < len(fitsFiles) - j:
            potential.append(fitsFiles[cur + j])
    # now go through files in this order and check if is successfully registered
    found = False
    for pot in potential:
        # fits file name of the next time
        tempName = os.path.splitext(pot)[0]
        # corresponding results file of the next time
        # if this file exists, the registration was successful for the tried file
        tsvFile  = tempName + '/' + tempName + '.tsv'
        # this is the file that is copied to the current computation directory,
        # if the registration was successful for the tried file
        headFile = tempName + '/' + tempName + '.head' 
        if os.path.isfile(tsvFile):
            found = True
            break
    # if something was found
    if found:
        print('File ' + base + ' FAILED but trying with different time ' + tempName)
        # copy the head file of the successful filter
        print('>> Copying new head file')
        shutil.copyfile(headFile, name + '/' + name + '.head')
        # rmove FAILED file
        print('>> Removing FAILED mark')
        try:
            os.remove(name + '/FAILED')
        except OSError:
            pass
        # remove old run/ directories
        print('>> Removing old run* folders')
        for run in glob.glob(name + '/run*'):
            shutil.rmtree(run)
        # and remove old diagnostics
        print('>> Removing old diagnostics')
        try:
            os.remove(name + '/diagnostics.html')
        except OSError:
            pass
        shutil.rmtree(name + '/.diagnostics', ignore_errors=True)
    else:
        print('File ' + base + ' FAILED and no other time has been registered yet')
        os._exit(1)
# if it failed previously, try sextractor in two-file mode with time stacking
elif os.path.isdir(name) and args.backup == 'sex' and args.use_time:
    # based on https://www.astro.ufl.edu/~ajtownsend/OBSTECH_REDUX_2017.html

    from astropy.io import fits
    from scipy.ndimage import interpolation as interp
    from skimage.feature.register_translation import (register_translation, _upsampled_dft)
    import numpy as np

    # list fits files in the same directory/filter
    fitsFiles = glob.glob("*.fits")
     # sort them by time
    fitsFiles = sorted(fitsFiles)
    # find the current file
    cur = fitsFiles.index(base)
    # find potential files that can help
    potential = list()
    for j in range(1, TDEPTH+1):
        # first look for files that are closest
        # look for immediate previous
        if cur > j-1:
            potential.append(fitsFiles[cur - j])
        # look for immediate after
        if cur < len(fitsFiles) - j:
            potential.append(fitsFiles[cur + j])
    # align the images
    print('File ' + base + ' FAILED but trying with sextractor double file mode with time stacked images')
    print('>> Aligning FITS files')
    # load fits images
    master_fits  = fits.getdata(args.file) # this is the other way around than with --sex-filter option
    other_fits = {}
    for image in potential:
        other_fits[image] = fits.getdata(image)
    # align
    shifted = {}
    for image in potential:
        result, error, diffphase = register_translation(master_fits, other_fits[image], 1000)
        shifted[image] = interp.shift(other_fits[image], result)
    # stack
    print('>> Stacking FITS files')
    stacked = np.stack(shifted.values(),axis=0)
    stacked = np.average(stacked, axis=0)
    # save (overwrite fits in the working directory which already exists because this is a backup branch)
    fits.writeto(filename=name + '/stacked.fits', data=stacked, header=fits.getheader(args.file), overwrite=True)
    # prepared special pp_run parameter for sextractor
    PP_SEX = '-sex stacked.fits,' + base
    # remove FAILED file
    print('>> Removing FAILED mark')
    try:
        os.remove(name + '/FAILED')
    except OSError:
        pass
    # remove old run* directories
    print('>> Removing old run* folders')
    for run in glob.glob(name + '/run*'):
        shutil.rmtree(run)
    # and remove old diagnostics
    print('>> Removing old diagnostics')
    try:
        os.remove(name + '/diagnostics.html')
    except OSError:
        pass
    shutil.rmtree(name + '/.diagnostics', ignore_errors=True)
# if it failed previously, try sextractor in two-file mode with help filter
elif os.path.isdir(name) and args.backup == 'sex':
    # if specified, use only the given filter
    if not args.use_filter == 'a':
        # check if the given filter was successful
        nameParts = name.split('_')
        tempName = nameParts[0] + '_' + nameParts[1] + '_' + IFOLDERS[args.use_filter] + '_' + nameParts[3]
        tsvFile  = '../' +  args.use_filter + '/' + tempName + '/' + tempName + '.tsv'
        if not os.path.isfile(tsvFile):
            print('File ' + base + ' FAILED and the specified filter was not successfully registered')
            os._exit(1)
            # stop here
        FILTERS = [IFOLDERS[args.use_filter]]
    else:
        thisFilter = name.split('_')[2]
        FILTERS.remove(thisFilter)
    # check if other filters are successfully registered:
    # break the current fits file name, so that correcponding name of the new filter
    # can be constructed
    nameParts = name.split('_')
    # to mark success
    found = False
    for fi in FILTERS:
        # fits file name of the next filter
        tempName = nameParts[0] + '_' + nameParts[1] + '_' + fi + '_' + nameParts[3]
        # corresponding results file of the next filter
        # if this file exists, the registration was successful for the tried filter
        tsvFile  = '../' +  FOLDERS[fi] + '/' + tempName + '/' + tempName + '.tsv'
        # this is the file that is copied to the current computation directory,
        # if the registration was successful for the tried filter
        headFile = '../' +  FOLDERS[fi] + '/' + tempName + '/' + tempName + '.head'
        # check if the tsv file exists
        # if not, continue to the next filter
        if not os.path.isfile(tsvFile):
            continue
        # if the tsv file exists (meaning the rgistration was successful for some filter),
        if os.path.isfile(headFile):
            found = True
            break
    # if there was a successful filter
    if found:
        
        from astropy.io import fits
        from scipy.ndimage import interpolation as interp
        from skimage.feature.register_translation import (register_translation, _upsampled_dft)

        # based on https://www.astro.ufl.edu/~ajtownsend/OBSTECH_REDUX_2017.html
        print('File ' + base + ' FAILED but trying with sextractor double file mode with filter ' + FOLDERS[fi])
        print('>> Aligning FITS files')
        # load fits images
        master_fits  = fits.getdata('../' +  FOLDERS[fi] + '/' + tempName + '.fits')
        current_fits = fits.getdata(args.file)
        # align
        result, error, diffphase = register_translation(master_fits, current_fits, 1000)
        shifted = interp.shift(current_fits, result) # only image data
        # save (overwrite fits in the working directory which already exists because this is a backup branch)
        fits.writeto(filename=name + '/' + args.file, data=shifted, header=fits.getheader(args.file), overwrite=True)
        # prepared special pp_run parameter for sextractor
        PP_SEX = '-sex ../../' +  FOLDERS[fi] + '/' + tempName + '.fits,' + base
        # also copy the head file of the successful filter
        print('>> Copying new head file') 
        shutil.copyfile(headFile, name + '/' + name + '.head')
        # remove FAILED file
        print('>> Removing FAILED mark')
        try:
            os.remove(name + '/FAILED')
        except OSError:
            pass
        # remove old run* directories
        print('>> Removing old run* folders')
        for run in glob.glob(name + '/run*'):
            shutil.rmtree(run)
        # and remove old diagnostics
        print('>> Removing old diagnostics')
        try:
            os.remove(name + '/diagnostics.html')
        except OSError:
            pass
        shutil.rmtree(name + '/.diagnostics', ignore_errors=True)
    else:
        print('File ' + base + ' FAILED and no other filter has been registered yet')
        os._exit(1)
# else
else:
    print('Processing file ' + base)

import sys
import subprocess
import shlex
import json
import tarfile
import numpy as np
import sqlite3
if args.dplots or args.iplots:
    from matplotlib import pyplot as plt
    from matplotlib.backends.backend_pdf import PdfPages
    from astropy.io import fits
    from astropy.visualization import ZScaleInterval

        
        
# load functions
def loadFile(filename):
    # loads *.dat file into memory
    # returns dictionary with "cols" and "vals"
    # values inside are most likely strings
    cols = []
    vals = []
    with open(filename,'r') as f:
        cols = f.readline()
        # last column contains space, so it needs to be fixed before split()
        # this is done by removing the part after the space
        if cols.find('APRAD') != -1:
            cols = cols[:-8]
        cols = cols.split()[1:]
        vals = f.readline().split()
    return {'cols': cols, 'vals': vals}
#
def loadResults(no_target=False):
    # loads *.dat files into memory (cumbersome due to variable/unknown object name)
    # by calling loadFile() function
    # returns dictionary
    for filename in glob.glob('*.dat'):
        filename = os.path.basename(filename)
        # astrometry results
        if filename == 'best_astrometry.dat':
            astro = loadFile(filename)
        # reference star
        elif filename == 'photometry_control_star.dat':
            star = loadFile(filename)
        # object
        else:
            Object = loadFile(filename)
    # return
    return {'astro': astro, 'star': star, 'object': None if no_target else Object}
#
def readSextractor(ldac_path='', force_file=''):
    if force_file == '':
        commandline = 'ldactoasc ' + ldac_path + name + '.ldac'
    else:
        commandline = 'ldactoasc ' + force_file

    print('>> Reading sextractor data (' + commandline + ')')
    try:
        ldac = subprocess.check_output(shlex.split(commandline))
    except Exception as e:
        print('>> FAILED reading ldac file (' + str(e) + ')')
        print('')
        return None
        
    # read out the output table
    ldac_ascii = [] # ldac file in ascii without header
    ldac_cols  = [] # column names for the ldac_ascii
    x = [] # x coord
    y = [] # y coord
    f = [] # fwhm
    for line in str(ldac)[2:].split('\\n'):
        # process header
        if line.startswith('#'):
            # extract 3rd column with the name
            ldac_cols.append(line.split()[2])
            continue
        # split into cols
        params = str(line).split()
        # skip short final line
        if len(params) < 29:
            continue
        # extract data
        x.append(float(params[17]))
        y.append(float(params[18]))
        f.append(float(params[25]))
        # save the data
        ldac_ascii.append(params)
        
    print('>> Sextractor identified ' + str(len(x)) + ' sources')
    
    # stop if force_file is set
    if not force_file == '':
        return {'x':x, 'y':y, 'f':f}

    # save sextractor data in ascii format
    print('>> Saving sextractor data in ascii (' + ldac_path + name + '.ldac.tsv)')
    with open(ldac_path + name + '.ldac.tsv', 'w')as fl:
        # write col names
        fl.write('\t'.join(ldac_cols) + '\n')
        # write data
        for item in ldac_ascii:
            fl.write('\t'.join([str(it) for it in item]) + '\n')

    # return data for plots
    return {'x':x, 'y':y, 'f':f}
#
def readScamp(scamp_path=''):
    # conenct to the database
    print('>> Connecting to SCAMP database (' + scamp_path + name + '.ldac.db)')
    try:
        sqlConnection = sqlite3.connect(scamp_path + name + '.ldac.db')
        sqlCursor = sqlConnection.cursor()
    except Exception as e:
        print('>> FAILED reading db file (' + str(e) + ')')
        print('')
        return None
    
    # read header
    print('>> Reading SCAMP header')
    sqlCursor.execute("SELECT * FROM data WHERE 1=0")
    scamp_cols = [d[0] for d in sqlCursor.description]
    
    # read data
    print('>> Reading SCAMP data')
    scamp_ascii = [] # scamp database in ascii
    x = [] # x coord
    y = [] # y coord
    f = [] # fwhm
    sqlCursor.execute('SELECT * FROM data')
    for row in sqlCursor:
        scamp_ascii.append(row)
        x.append(float(row[17]))
        y.append(float(row[18]))
        f.append(float(row[25]) + 3)
        
    print('>> SCAMP registered ' + str(len(x)) + ' sources')
    
    # save SCAMP data in ascii format
    print('>> Saving SCAMP data in ascii (' + scamp_path + name + '.ldac.db.tsv)')
    with open(scamp_path + name + '.ldac.db.tsv', 'w')as fl:
        # write col names
        fl.write('\t'.join(scamp_cols) + '\n')
        # write data
        for item in scamp_ascii:
            fl.write('\t'.join([str(it) for it in item]) + '\n')
            
    # return data for plots
    return {'x':x, 'y':y, 'f':f}
#
def readCat(filename, cent_ra, cent_de):
    
    commandline = 'ldactoasc ' + filename
    print('>> Reading catalogue data (' + commandline + ')')
    try:
        ldac = subprocess.check_output(shlex.split(commandline))
    except Exception as e:
        print('>> FAILED reading cat file (' + str(e) + ')')
        print('')
        return None
        
    # read out the output table
    stars = 0
    for line in str(ldac)[2:].split('\\n'):
        # split into cols
        params = str(line).split()
        # skip short final line
        if len(params) < 7:
            continue
            
        RA = float(params[0])
        DE = float(params[1])
        MG = float(params[4])
        
        # skip if not in the field of view
        RA_dist = np.min([np.abs(RA - cent_ra), 360 - np.abs(RA - cent_ra)])
        DE_dist = np.min([np.abs(DE - cent_de), 360 - np.abs(DE - cent_de)])

        if RA_dist > DIM_X/2 or DE_dist > DIM_Y/2:
            continue
            
        # skipt if too faint
        if MG > 19:
            continue
            
        # if not, count the star
        stars += 1
        
    return stars
#
def plotDetections(sex, sex2, scm):

    if not args.dplots:
        print('>> Skipping detection plots (missing --dplots option)')
        return None
    else:
        print('>> Making detection plots')

    # open fits file for graphics
    print('>> Loading fits file image')
    image_data = fits.getdata(name + '.fits')
    
    # zscale
    if args.zscale:
        zscale      = ZScaleInterval()
        zmin, zmax  = zscale.get_limits(image_data)
        image_data  = np.where(image_data > zmin, image_data, zmin)
        image_data  = np.where(image_data < zmax, image_data, zmax)
        scaled_data = (image_data - zmin) * (255.0 / (zmax - zmin)) + 0.5
    else:
        scaled_data = image_data
        
    # plot fits image
    fig = plt.imshow(scaled_data, cmap='gray')
    
    # add main sextractor detextions to plot
    print('>> Adding main sextractor detections')
    # add sextractor identified sources
    x = sex['x']
    y = sex['y']
    f = sex['f']
    for i in range(len(x)):
        circle = plt.Circle((x[i], y[i]), f[i], color='red', linewidth=0.1, fill=False)
        plt.gcf().gca().add_artist(circle)
        
    if not sex2 == None:
        # add help sextractor detextions to plot
        print('>> Adding help sextractor detections')
        # add sextractor identified sources
        x = sex2['x']
        y = sex2['y']
        f = sex2['f']
        for i in range(len(x)):
            circle = plt.Circle((x[i], y[i]), f[i], color='green', linewidth=0.1, linestyle='-', fill=False)
            plt.gcf().gca().add_artist(circle)

    # if the registration was successful, mark scamp database in the image
    if not scm == None:
        x = scm['x']
        y = scm['y']
        f = scm['f']
        print('>> Adding SCAMP data')
        for i in range(len(x)):
            circle = plt.Circle((x[i], y[i]), f[i], color='blue', linewidth=0.1, fill=False)
            plt.gcf().gca().add_artist(circle)
    else:
        print('>> No SCAMP data to add')
    # done
    return fig
#
def saveDetections(detections, ITERS):
    with PdfPages('detections.pdf') as pdf:
        for i in range(ITERS):
            if detections[i] == None:
                fig = plt.figure()
            else:
                fig = plt.figure(detections[i].figure.number)
            pdf.savefig()
#
def run(i):
    print('')
    print('=========== Starting run ' + str(i))

    # create run directory for storing results
    runDir = 'run' + str(i)
    print('>> Creating run directory (' + runDir + ')')
    if not os.path.exists(runDir):
        os.makedirs(runDir)
    
    # prepare error file
    print('>> Setting pipeline error file to ' + runDir + '/error.txt')
    STDERR = open(runDir + '/err.txt', 'w')
    
    # pipeline command
    commandline = 'pp_run'
    # add target
    if not args.target == '':
        commandline += ' -target ' + args.target
    # add filter
    if not args.filter == '':
        commandline += ' -filter ' + args.filter
    # add aperture
    if not args.fixed_aprad == 0:
        commandline += ' -fixed_aprad ' + str(args.fixed_aprad)
    if args.solar:
        commandline += ' -solar'
    # special params
    if not PP_SEX == '':
        commandline += ' ' + PP_SEX
    if STARFIELD:
        commandline += ' -starfield'
    # add image
    commandline += ' ' + base
        
    print('>> Running pipeline command \'' + commandline + '\'')
    
    abort = False
    try:
        pp = subprocess.check_output(shlex.split(commandline), stderr=STDERR).decode("utf-8").splitlines()
    except Exception as e:
        # if pp_run breaks
        print('>> Pipeline ERROR: ' + str(e))
        # store the error
        STDERR.writelines(['', '>> Pipeline ERROR: ' + str(e)])
        abort = True
    # close and write errors from pipelien    
    STDERR.close()
    
    # try to read sextractor data
    if not os.path.isfile(name + '.ldac'):
        print('>> MISSING ldac file?! What happened sextractor?')
        print('>> Stopping run')
        return None, None
    else:
        sex = readSextractor() # still can be None
    
    # if backup == sex, read also help filter sextractor data for plots
    if args.backup == 'sex' and not args.use_time:
        helpFilter = PP_SEX.split('/')[2]
        helpName   = PP_SEX.split('/')[3].split('.')[0]
        sex2 = readSextractor(force_file='../../' + helpFilter + '/' + helpName + '/run3/' + helpName + '.ldac')
    else:
        sex2 = None

    # try to read SCAMP data
    if not os.path.isfile(name + '.ldac.db'):
        print('>> MISSING SCAMP db file')
        scm = None
    else:
        scm = readScamp() # still can be None
    
    # try to make detection plots
    if not sex == None:
        pd = plotDetections(sex, sex2, scm) # still can be None
    else:
        pd = None
        
    
    #  if the pipeline failed, abort run
    if abort:
        print('>> Stopping run')
        return None, pd
        
    
    # save pp_run output
    print('>> Saving pipeline output to ' + runDir + '/out.txt')
    with open(runDir + '/out.txt', 'w') as f:
        f.writelines([str(l) + '\n' for l in pp])
    
    # move ldac file (at this point it must exist)
    print('>> Moving ldac file to run directory')
    commandline = 'mv ' + name + '.ldac ' + name + '.ldac.tsv ' + runDir + '/'
    try:
        mv = subprocess.call(shlex.split(commandline))
    except Exception as e:
        print('>> FAILED (' + str(e) + ')')
    
    # move SCAMP data if it exists
    if os.path.isfile(name + '.ldac.db'):
        print('>> Moving SCAMP data to run directory')
        commandline = 'mv ' + name + '.ldac.db ' + name + '.ldac.db.tsv ' + runDir + '/'
        try:
            mv = subprocess.call(shlex.split(commandline))
        except Exception as e:
            print('>> FAILED (' + str(e) + ')')
            
    # read the number of stars in catalogue (assuming the name *.cat and ldac format)
    # extract direction from *.head file
    if os.path.isfile(name + '.head'):
        with open(name + '.head', 'r') as f:
            lines = f.readlines()
        for line in lines:
            params = line.split()
            if params[0] == 'CRVAL1':
                cent_ra = float(params[2])
            if params[0] == 'CRVAL2':
                cent_de = float(params[2])
        # read all catalogues, could be more than one
        catFiles = glob.glob('*.cat')
        for Cat in catFiles:
            try:
                n = readCat(Cat, cent_ra, cent_de)
                print('>> Catalogue ' + Cat + ' has ' + str(n) + ' stars')
            except Exception as e:
                print('>> Catalogue ' + Cat + ' has unknown format (' + str(e) + ')')
            
    # if there are results, move them to run directory
    datFiles = glob.glob('*.dat')
    if len(datFiles) == 3 or (len(datFiles) == 2 and STARFIELD):
        # load *.dat files to memory
        print('>> Loading results (*.dat files) to memory')
        results = loadResults(no_target=STARFIELD)
        
        print('>> Moving results (*.dat files) to run directory')
        # move *.dat files to run folder
        commandline = 'mv *.dat ' + runDir + '/'
        for dat in datFiles:
            commandline = 'mv ' + dat + ' ' + runDir + '/' + os.path.basename(dat)
            try:
                mv = subprocess.call(shlex.split(commandline))
            except Exception as e:
                # if failed, stop the run
                print('>> FAILED (' + str(e) + '), stopping run')
                return None, pd
                
        # return
        print('>> Registration PASSED (AS_CONTRAST = ' + str(results['astro']['vals'][1]) + ', XY_CONTRAST = ' + str(results['astro']['vals'][2]) + ')')
        return results, pd
    elif len(datFiles) == 2 and not STARFIELD:
        print('>> MISSING one result file (check target name in fits file or use --target option), stopping')
        print('')
        # no point to continue, the problem will repeat
        f = open('FAILED','w')
        f.close()
        os._exit(1)
    else:
        print('>> Registration FAILED')
        return None, pd
#
def prepareData(results, ITERS):
    x_axis = {
        'iteration': [],
        'as_cont'  : [],
        'xy_cont'  : []
    }
    x_axis_label = {'iteration': 'iteration', 'as_cont': 'AS_CONTRAST', 'xy_cont': 'XY_CONTRAST'}

    y_axis = {
        'obj_mag'  : [],
        'obj_magS' : [],
        'obj_ra'   : [],
        'obj_dec'  : [],
        'star_mag' : [],
        'star_magS': [],
        'star_ra'  : [],
        'star_dec' : []
    }
    y_axis_label = {'obj_mag': 'Object magnitude', 'obj_ra': 'Object RA', 'obj_dec': 'Object DEC', 'star_mag': 'Star magnitude', 'star_ra': 'Star RA', 'star_dec': 'Star DEC'}

    for i in range(ITERS):
    
        if results[i] == None:
            continue
        
        if results[i] == 'null':
            continue
        
        x_axis['iteration'].append(int(i)+1)
        x_axis['as_cont'].append(float(results[i]['astro']['vals'][1]))
        x_axis['xy_cont'].append(float(results[i]['astro']['vals'][2]))

        y_axis['obj_mag'].append(float(results[i]['object']['vals'][2]))
        y_axis['obj_magS'].append(float(results[i]['object']['vals'][3]))
        y_axis['obj_ra'].append(float(results[i]['object']['vals'][4]))
        y_axis['obj_dec'].append(float(results[i]['object']['vals'][5]))
        
        y_axis['star_mag'].append(float(results[i]['star']['vals'][2]))
        y_axis['star_magS'].append(float(results[i]['star']['vals'][3]))
        y_axis['star_ra'].append(float(results[i]['star']['vals'][4]))
        y_axis['star_dec'].append(float(results[i]['star']['vals'][5]))
    
    for key in x_axis.keys():
        x_axis[key] = np.asarray(x_axis[key])
    for key in y_axis.keys():
        y_axis[key] = np.asarray(y_axis[key])

    return {'x': x_axis, 'xlab': x_axis_label, 'y': y_axis, 'ylab': y_axis_label}
#
def makePlots(data):
    x    = data['x']
    xlab = data['xlab']
    y    = data['y']
    ylab = data['ylab']

    fig, axarr = plt.subplots(2, 2, sharex=True, figsize=(18,12))

    # contrast plots
    axarr[0,0].plot(x['iteration'], x['xy_cont'], 'b-', label='XY_CONTRAST')
    axarr[0,0].plot(x['iteration'], x['as_cont'], 'r-', label='AS_CONTRAST')
    axarr[0,0].set_title('Contrast vs. iteration')
    axarr[0,0].set_ylabel('Contrast')
    axarr[0,0].legend()

    # magnitude plots
    axarr[0,1].plot(x['iteration'], y['obj_mag'],                   'b-',  label='Object mag.')
    axarr[0,1].plot(x['iteration'], y['obj_mag'] - y['obj_magS'],   'b--', label='Object mag. - SD') 
    axarr[0,1].plot(x['iteration'], y['obj_mag'] + y['obj_magS'],   'b--', label='Object mag. + SD') 

    axarr[0,1].plot(x['iteration'], y['star_mag'],                  'r-',  label='Star mag.')
    axarr[0,1].plot(x['iteration'], y['star_mag'] - y['star_magS'], 'r--', label='Star mag. - SD') 
    axarr[0,1].plot(x['iteration'], y['star_mag'] + y['star_magS'], 'r--', label='Star mag. + SD') 
    
    axarr[0,1].set_title('Magnitude vs. iteration')
    axarr[0,1].set_ylabel('Magnitude')
    axarr[0,1].legend()

    # position plots
    axarr[1,0].plot(x['iteration'], y['obj_ra'],  'b-', label='Object')
    axarr[1,0].plot(x['iteration'], y['star_ra'], 'r-', label='Star')
    axarr[1,0].set_title('Right Ascention')
    axarr[1,0].set_ylabel('Right ascention [deg]')
    axarr[1,0].set_xlabel('Iteration')
    axarr[1,0].legend()

    axarr[1,1].plot(x['iteration'], y['obj_dec'],  'b-', label='Object')
    axarr[1,1].plot(x['iteration'], y['star_dec'], 'r-', label='Star')
    axarr[1,1].set_title('Declination')
    axarr[1,1].set_ylabel('Declination [deg]')
    axarr[1,1].set_xlabel('Iteration')
    axarr[1,1].legend()

    return fig
#
def pp_plotter(results, ITERS):
    # prepare plot data
    data = prepareData(results, ITERS)

    # make plots
    with PdfPages(name + '.pdf') as pdf:
        fig = makePlots(data)
        pdf.savefig()  # saves the current figure into a pdf page
#


# create computation folder
workDir = path + '/' + name
print('>> Creating computation directory (' + workDir + ')')
if not os.path.exists(workDir):
    os.makedirs(workDir)

# copy fits file to the working directory
if not args.backup == 'sex':
    print('>> Copying fits file to computation directory')
    shutil.copyfile(args.file, workDir + '/' + base)

# set working directory
print('>> Setting working directory to ' + workDir)
os.chdir(workDir)

# results
master_results = {}
detection_plots = {}


#
# THE MAIN LOOP ##############################
#


# count initial Nones. if there are three, there is 
# very little chance the file will succeed. 
NoneCount = 0
# switch this, if there are three initial Nones
failedToStart = False
brokenPipeline = False
lastSuccess = -1
for i in range(ITERS):
    # check for consecutive Nones
    if NoneCount > 2:
        failedToStart = True
        break
        
        
    # main part
    try:
        master_results[i], detection_plots[i] = run(i+1)
    except Exception as e:
        print('>> Something went terribly wrong (' + str(e) + ')')
        brokenPipeline = True
        break
        
    
    # update NoneCount
    if master_results[i] == None and lastSuccess == -1:
        NoneCount += 1
    
    # update last successful run
    if not master_results[i] == None:
        lastSuccess = i
    
    # consider stopping the loop:
    # was there enough iterations?
    if i<2:
        continue
    # did one of the last three iterations fail?
    if master_results[i] == None or master_results[i-1] == None:
        continue
    # were last three AS_CONTRAST close enough?
    as_0 = float(master_results[i]  ['astro']['vals'][1])
    as_1 = float(master_results[i-1]['astro']['vals'][1])
    if not np.abs(as_0 - as_1) < 1:
        continue
    # were last three XY_CONTRAST close enough?
    xy_0 = float(master_results[i]  ['astro']['vals'][2])
    xy_1 = float(master_results[i-1]['astro']['vals'][2])
    if not np.abs(xy_0 - xy_1) < 1:
        continue
    # now the loop can be stopped
    break
#

if failedToStart:
    i = i - 1

print('')
print('========== Finished on run ' + str(i+1))
print('')

# check how to loop stopped:
# something unexpected happened
if brokenPipeline:
    print('>> FAILED on ' + str(i) + 'th iteration')
    # set FAILED mark
    f = open('FAILED','w')
    f.close()
    # create detection plots if selected
    if args.dplots:
        print('>> Saving sextractor detections plots (detections.pdf)')
        saveDetections(detection_plots, i+1)
    print('>>>>>>>>>> Done')
    print('')
    # pipeline broke, stopping
    os._exit(1)
# failed to produce registration in first three runs
elif failedToStart:
    print('FAILED to register')
    # set FAILED mark
    f = open('FAILED','w')
    f.close()
    # create detection plots if selected
    if args.dplots:
        print('Saving sextractor detections plots (detections.pdf)')
        saveDetections(detection_plots, i+1)
    print('>>>>>>>>>> Done')
    print('')
    # pipeline failed to start, stopping
    os._exit(1)
# the last run is None
# but there was a successfull registration before
elif master_results[i] == None and lastSuccess > -1:
    print('')
    print('>> Last run returned None but there was success before')
    i = lastSuccess

# pipeline (at least at one point) successful
savename = name + '.json'
print('>> Saving results to ' + savename)
json.dump(master_results, open(savename,'w'))

print('>> Saving final run to ' + name + '.tsv')

# add astrometry
cols = master_results[i]['astro']['cols']
vals = master_results[i]['astro']['vals']

# add object
if STARFIELD:
    # no object, just add zeros
    cols = cols + master_results[i]['star']['cols']
    vals = vals + ['0']*len(master_results[i]['star']['cols'])
else:
    cols = cols + master_results[i]['object']['cols']
    vals = vals + master_results[i]['object']['vals']

# add star
cols = cols + master_results[i]['star']['cols']
vals = vals + master_results[i]['star']['vals']
with open(name + '.tsv', 'w') as f:
    f.write('\t'.join(cols))
    f.write('\n')
    f.write('\t'.join(vals))
    f.write('\n')

if args.dplots:
    print('>> Saving sextractor detections plots (detections.pdf)')
    saveDetections(detection_plots, i+1)

if args.iplots:
    print('>> Making iteration plots (' + name + '.pdf)')
    try:
        pp_plotter(master_results, i+1)
    except Exception as e:
        print('')
        print('>> Plotting FAILED: ' + str(e) + ', skipping')
        print('')

if args.gzip:
    # remove the modified fits file
    print('>> Removing processed fits file')
    os.remove(base)

    # compress the results folder
    print('>> Compressing the results')
    os.chdir('..')
    tar = tarfile.open(name + '.tar.gz', 'w:gz')
    tar.add(name, arcname=name)
    tar.close()

    # remove the uncompressed results
    print('>> Removing uncompressed results')
    shutil.rmtree(name)

print('>>>>>>>>>> Done')
print('')
